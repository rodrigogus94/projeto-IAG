# app.py - Layout moderno com sidebar de chat
import streamlit as st
import os
from typing import Optional
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente do arquivo .env
load_dotenv()

# Imports dos m√≥dulos customizados
try:
    from llm_handler import create_llm_handler
    from audio_transcriber import transcribe_audio
    from styles import CUSTOM_CSS

    LLM_AVAILABLE = True
    AUDIO_AVAILABLE = True
except ImportError as e:
    LLM_AVAILABLE = False
    AUDIO_AVAILABLE = False
    CUSTOM_CSS = ""
    st.warning(f"‚ö†Ô∏è Alguns m√≥dulos n√£o foram encontrados: {str(e)}")

    # Fallback para create_llm_handler
    def create_llm_handler(base_url=None):
        return None


# Configura√ß√£o da p√°gina com layout wide
st.set_page_config(
    page_title="Omnilink AI",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSS customizado importado de styles.py
if CUSTOM_CSS:
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# Adicionar CSS espec√≠fico para altern√¢ncia microfone/seta
st.markdown(
    """
<style>
/* Container principal para chat input */
.chat-input-wrapper {
    position: relative;
    width: 100%;
}

/* Esconder completamente o label do audio input */
div[data-testid="stAudioInput"] label {
    display: none !important;
}

/* Posicionar o audio input ao lado do bot√£o de envio */
div[data-testid="stAudioInput"] {
    position: absolute !important;
    right: 45px !important;
    top: 50% !important;
    transform: translateY(-50%) !important;
    z-index: 1000 !important;
    width: auto !important;
}

/* Estilizar o bot√£o do audio input */
div[data-testid="stAudioInput"] button {
    background: transparent !important;
    border: none !important;
    padding: 8px !important;
    min-width: 40px !important;
    width: 40px !important;
    height: 40px !important;
    border-radius: 50% !important;
    display: flex !important;
    align-items: center !important;
    justify-content: center !important;
    font-size: 1.3rem !important;
    color: #666 !important;
    transition: all 0.2s ease !important;
}

div[data-testid="stAudioInput"] button:hover {
    background: rgba(102, 126, 234, 0.1) !important;
    color: #667eea !important;
}

/* Ocultar microfone quando h√° texto */
.hide-microphone div[data-testid="stAudioInput"] {
    opacity: 0 !important;
    pointer-events: none !important;
}

/* Mostrar microfone quando n√£o h√° texto */
.show-microphone div[data-testid="stAudioInput"] {
    opacity: 1 !important;
    pointer-events: all !important;
}

/* Ocultar seta de envio quando n√£o h√° texto */
.hide-send-button button[aria-label="Send"] {
    opacity: 0 !important;
    pointer-events: none !important;
}

/* Mostrar seta de envio quando h√° texto */
.show-send-button button[aria-label="Send"] {
    opacity: 1 !important;
    pointer-events: all !important;
}

/* Indicador de pensando */
.thinking-indicator {
    text-align: center;
    color: #667eea;
    font-style: italic;
    margin: 10px 0;
    padding: 8px;
    background: rgba(102, 126, 234, 0.1);
    border-radius: 8px;
    font-size: 0.9rem;
}
</style>
""",
    unsafe_allow_html=True,
)

# JavaScript para altern√¢ncia microfone/seta
st.markdown(
    """
<script>
// Fun√ß√£o para configurar a altern√¢ncia
function setupMicrophoneToggle() {
    // Encontrar todos os containers de chat
    const chatInputs = document.querySelectorAll('[data-testid="stChatInput"]');
    
    chatInputs.forEach((chatInput, index) => {
        // Criar wrapper se n√£o existir
        let wrapper = chatInput.closest('.chat-input-wrapper');
        if (!wrapper) {
            wrapper = document.createElement('div');
            wrapper.className = 'chat-input-wrapper hide-send-button show-microphone';
            chatInput.parentNode.insertBefore(wrapper, chatInput);
            wrapper.appendChild(chatInput);
        }
        
        // Encontrar elementos
        const textInput = chatInput.querySelector('input[type="text"]');
        const sendButton = chatInput.querySelector('button[aria-label="Send"]');
        
        if (!textInput || !sendButton) return;
        
        // Fun√ß√£o para atualizar visibilidade
        function updateVisibility() {
            const hasText = textInput.value.trim().length > 0;
            
            if (hasText) {
                // Tem texto: mostrar seta, ocultar microfone
                wrapper.classList.remove('hide-send-button');
                wrapper.classList.add('show-send-button');
                wrapper.classList.add('hide-microphone');
                wrapper.classList.remove('show-microphone');
            } else {
                // Sem texto: mostrar microfone, ocultar seta
                wrapper.classList.add('hide-send-button');
                wrapper.classList.remove('show-send-button');
                wrapper.classList.remove('hide-microphone');
                wrapper.classList.add('show-microphone');
            }
        }
        
        // Configurar listeners
        textInput.addEventListener('input', updateVisibility);
        textInput.addEventListener('keyup', updateVisibility);
        
        // Atualizar inicialmente
        updateVisibility();
        
        // Verificar periodicamente (fallback)
        setInterval(updateVisibility, 500);
    });
}

// Executar quando o DOM estiver pronto
if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', setupMicrophoneToggle);
} else {
    setTimeout(setupMicrophoneToggle, 1000);
}

// Reexecutar quando o Streamlit atualizar a p√°gina
let observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
        if (mutation.addedNodes.length > 0) {
            setTimeout(setupMicrophoneToggle, 500);
        }
    });
});

observer.observe(document.body, {
    childList: true,
    subtree: true
});
</script>
""",
    unsafe_allow_html=True,
)

# Inicializa√ß√£o do session_state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "llm_handler" not in st.session_state:
    st.session_state.llm_handler = None

if "selected_model" not in st.session_state:
    st.session_state.selected_model = "llama2:latest"

if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7

if "prompt_in_center" not in st.session_state:
    st.session_state.prompt_in_center = False

if "audio_transcribed" not in st.session_state:
    st.session_state.audio_transcribed = None

if "is_thinking" not in st.session_state:
    st.session_state.is_thinking = False

if "ollama_url" not in st.session_state:
    st.session_state.ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

if "transcription_method" not in st.session_state:
    st.session_state.transcription_method = os.getenv("TRANSCRIPTION_METHOD", "whisper")

# Auto-inicializa√ß√£o do Ollama
if st.session_state.llm_handler is None:
    try:
        st.session_state.llm_handler = create_llm_handler(st.session_state.ollama_url)
        if (
            st.session_state.llm_handler
            and st.session_state.llm_handler.is_configured()
        ):
            st.session_state.llm_handler = st.session_state.llm_handler
    except Exception:
        st.session_state.llm_handler = None

# ========== SIDEBAR ESQUERDA - CHAT ==========
with st.sidebar:
    # Header com gradiente roxo
    st.markdown(
        """
        <div class="sidebar-header">
            <div class="sidebar-title">
                ü§ñ Omnilink AI
            </div>
            <div class="sidebar-subtitle">
                Assistente de Dashboards Inteligentes
            </div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # Mensagem de boas-vindas
    st.markdown(
        """
        <div class="welcome-message">
            <strong>Ol√°! üëã</strong><br>
            Sou seu assistente de dashboards. Pe√ßa visualiza√ß√µes de dados e eu gero para voc√™ em tempo real!
        </div>
        """,
        unsafe_allow_html=True,
    )

    # Container para hist√≥rico de mensagens (scroll√°vel)
    chat_history_container = st.container()
    with chat_history_container:
        if st.session_state.messages:
            for message in st.session_state.messages:
                if message["role"] == "user":
                    st.markdown(
                        f'<div class="chat-message" style="background: #f0f0f0;"><strong>Voc√™:</strong> {message["content"]}</div>',
                        unsafe_allow_html=True,
                    )
                else:
                    st.markdown(
                        f'<div class="chat-message" style="background: #e8f4f8;"><strong>Assistente:</strong> {message["content"]}</div>',
                        unsafe_allow_html=True,
                    )
        else:
            st.markdown(
                '<div style="text-align: center; color: #999; padding: 2.5rem 1rem; font-size: 0.95rem;">Nenhuma mensagem ainda</div>',
                unsafe_allow_html=True,
            )

    st.markdown("<br>", unsafe_allow_html=True)

    # Mostrar indicador de pensando acima do prompt se estiver pensando
    if st.session_state.is_thinking:
        st.markdown(
            '<div class="thinking-indicator">üí≠ <em>Pensando...</em></div>',
            unsafe_allow_html=True,
        )

    # Container integrado para prompt e microfone
    user_input = None
    audio_file = None

    if not st.session_state.prompt_in_center:
        # Input de mensagem usando chat_input
        user_input = st.chat_input("Digite sua mensagem...", key="sidebar_chat_input")

        # Microfone posicionado ao lado do bot√£o de envio via CSS
        audio_file = st.audio_input(
            "üéôÔ∏è", key="sidebar_audio", help="Clique para gravar uma mensagem de voz"
        )

        # Processar √°udio se fornecido
        if audio_file:
            st.audio(audio_file, format="audio/wav")
            with st.spinner("Transcrevendo √°udio..."):
                try:
                    if AUDIO_AVAILABLE:
                        transcribed_text = transcribe_audio(
                            audio_file, method=st.session_state.transcription_method
                        )
                        if transcribed_text:
                            st.session_state.audio_transcribed = transcribed_text
                        else:
                            st.error(
                                "‚ùå Erro ao transcrever √°udio. Verifique se o servi√ßo est√° configurado."
                            )
                    else:
                        st.warning(
                            "‚ö†Ô∏è Transcri√ß√£o de √°udio n√£o dispon√≠vel. Instale as depend√™ncias necess√°rias."
                        )
                except Exception as e:
                    st.error(f"‚ùå Erro na transcri√ß√£o: {str(e)}")

            if st.session_state.audio_transcribed:
                st.info(
                    f"üìù Transcri√ß√£o do √°udio: **{st.session_state.audio_transcribed}**"
                )
                # Se houver transcri√ß√£o, usar como input
                if not user_input:
                    user_input = st.session_state.audio_transcribed
                    st.session_state.audio_transcribed = None  # Limpar ap√≥s usar

    st.markdown("---")

    # Configura√ß√µes (colaps√°vel)
    with st.expander("‚öôÔ∏è Configura√ß√µes"):
        # Configura√ß√£o do Ollama
        st.markdown("### üîß Configura√ß√£o do Ollama")
        ollama_url = st.text_input(
            "URL do servidor Ollama",
            value=st.session_state.ollama_url,
            help="URL padr√£o: http://localhost:11434",
        )

        if ollama_url != st.session_state.ollama_url:
            st.session_state.ollama_url = ollama_url
            try:
                st.session_state.llm_handler = create_llm_handler(ollama_url)
                if (
                    st.session_state.llm_handler
                    and st.session_state.llm_handler.is_configured()
                ):
                    st.success("‚úÖ Conectado ao Ollama!")
                else:
                    st.warning("‚ö†Ô∏è Ollama n√£o est√° dispon√≠vel nesta URL")
            except Exception as e:
                st.error(f"‚ùå Erro ao conectar: {str(e)}")
                st.session_state.llm_handler = None

        # Bot√£o para reconectar
        if st.button("üîÑ Reconectar ao Ollama", use_container_width=True):
            try:
                st.session_state.llm_handler = create_llm_handler(
                    st.session_state.ollama_url
                )
                if (
                    st.session_state.llm_handler
                    and st.session_state.llm_handler.is_configured()
                ):
                    st.success("‚úÖ Conectado com sucesso!")
                    st.rerun()
                else:
                    st.error(
                        "‚ùå N√£o foi poss√≠vel conectar ao Ollama. Verifique se o servidor est√° rodando."
                    )
            except Exception as e:
                st.error(f"‚ùå Erro: {str(e)}")

        # Sele√ß√£o de modelo - buscar dinamicamente do Ollama
        try:
            if st.session_state.llm_handler:
                available_models = st.session_state.llm_handler.list_available_models()
                if available_models:
                    # Se o modelo atual n√£o est√° na lista, usar o primeiro dispon√≠vel
                    if st.session_state.selected_model not in available_models:
                        st.session_state.selected_model = available_models[0]

                    current_index = (
                        available_models.index(st.session_state.selected_model)
                        if st.session_state.selected_model in available_models
                        else 0
                    )
                    st.session_state.selected_model = st.selectbox(
                        "Modelo Ollama", available_models, index=current_index
                    )
                else:
                    st.warning(
                        "‚ö†Ô∏è Nenhum modelo encontrado. Baixe modelos usando: ollama pull <nome_do_modelo>"
                    )
                    st.session_state.selected_model = st.text_input(
                        "Digite o nome do modelo", value=st.session_state.selected_model
                    )
            else:
                st.warning("‚ö†Ô∏è Conecte ao Ollama primeiro")
                st.session_state.selected_model = st.text_input(
                    "Nome do modelo", value=st.session_state.selected_model
                )
        except Exception as e:
            st.error(f"Erro ao listar modelos: {str(e)}")
            st.session_state.selected_model = st.text_input(
                "Nome do modelo", value=st.session_state.selected_model
            )

        # Controle de temperatura
        st.session_state.temperature = st.slider(
            "Criatividade (temperature)",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1,
        )

        st.markdown("---")

        # Configura√ß√£o de transcri√ß√£o de √°udio
        st.markdown("### üéôÔ∏è Transcri√ß√£o de √Åudio")
        transcription_method = st.selectbox(
            "M√©todo de transcri√ß√£o",
            ["whisper", "openai"],
            index=0 if st.session_state.transcription_method == "whisper" else 1,
            help="Whisper: local (requer openai-whisper). OpenAI: API (requer OPENAI_API_KEY)",
        )
        st.session_state.transcription_method = transcription_method

        if transcription_method == "openai":
            openai_key = os.getenv("OPENAI_API_KEY", "")
            if not openai_key:
                st.warning("‚ö†Ô∏è OPENAI_API_KEY n√£o encontrada no .env para transcri√ß√£o")

        st.markdown("---")

        # Configura√ß√£o de posi√ß√£o do prompt
        st.markdown("**üìç Posi√ß√£o do Prompt**")
        prompt_in_center = st.checkbox(
            "Prompt no centro (abaixo)",
            value=st.session_state.prompt_in_center,
            help="Quando ativado, o prompt fica fixo no centro inferior da tela. Recomendado quando a sidebar est√° escondida.",
        )

        if prompt_in_center != st.session_state.prompt_in_center:
            st.session_state.prompt_in_center = prompt_in_center
            st.rerun()

        if prompt_in_center:
            st.info(
                "üí° O prompt est√° configurado para aparecer no centro inferior da tela."
            )
        else:
            st.info(
                "üí° Dica: Se esconder a sidebar, ative esta op√ß√£o para mover o prompt para o centro."
            )

        # Bot√£o limpar chat
        if st.button("üóëÔ∏è Limpar Chat", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

    st.markdown("---")

    # Status do Sistema (na sidebar)
    with st.expander("üîß Status do Sistema", expanded=False):
        # Preparar valores do status
        handler_available = "‚úÖ Sim" if LLM_AVAILABLE else "‚ùå N√£o"
        handler_available_color = "#28a745" if LLM_AVAILABLE else "#dc3545"

        handler_initialized = (
            "‚úÖ Sim" if st.session_state.llm_handler is not None else "‚ùå N√£o"
        )
        handler_initialized_color = (
            "#28a745" if st.session_state.llm_handler is not None else "#dc3545"
        )

        ollama_configured = (
            "‚úÖ Sim"
            if (
                st.session_state.llm_handler
                and st.session_state.llm_handler.is_configured()
            )
            else "‚ùå N√£o"
        )
        ollama_configured_color = (
            "#28a745"
            if (
                st.session_state.llm_handler
                and st.session_state.llm_handler.is_configured()
            )
            else "#dc3545"
        )

        audio_available = "‚úÖ Sim" if AUDIO_AVAILABLE else "‚ùå N√£o"
        audio_available_color = "#28a745" if AUDIO_AVAILABLE else "#dc3545"

        num_messages = len(st.session_state.messages)
        current_model = st.session_state.selected_model

        st.markdown(
            f"""
            <div class="status-container">
                <div class="status-item">
                    <span class="status-label">Handler Dispon√≠vel</span>
                    <span class="status-value" style="color: {handler_available_color};">
                        {handler_available}
                    </span>
                </div>
                <div class="status-item">
                    <span class="status-label">Handler Inicializado</span>
                    <span class="status-value" style="color: {handler_initialized_color};">
                        {handler_initialized}
                    </span>
                </div>
                <div class="status-item">
                    <span class="status-label">Ollama Conectado</span>
                    <span class="status-value" style="color: {ollama_configured_color};">
                        {ollama_configured}
                    </span>
                </div>
                <div class="status-item">
                    <span class="status-label">Transcri√ß√£o de √Åudio</span>
                    <span class="status-value" style="color: {audio_available_color};">
                        {audio_available}
                    </span>
                </div>
                <div class="status-item">
                    <span class="status-label">Mensagens no Hist√≥rico</span>
                    <span class="status-value" style="color: #667eea;">
                        {num_messages}
                    </span>
                </div>
                <div class="status-item">
                    <span class="status-label">Modelo Atual</span>
                    <span class="status-value" style="color: #667eea;">
                        {current_model}
                    </span>
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

# Processar mensagem quando enviada da sidebar (texto ou √°udio transcrito)
if user_input:
    if (
        st.session_state.llm_handler is None
        or not st.session_state.llm_handler.is_configured()
    ):
        st.error("‚ö†Ô∏è Ollama n√£o est√° dispon√≠vel. Verifique se o servidor est√° rodando.")
    else:
        # Adicionar mensagem do usu√°rio no hist√≥rico
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Exibir imediatamente a mensagem do usu√°rio
        with st.chat_message("user"):
            st.markdown(user_input)

        # Gerar resposta em streaming
        with st.chat_message("assistant"):
            placeholder = st.empty()
            full_response = ""

            # Gerar resposta
            response = st.session_state.llm_handler.generate_response(
                messages=st.session_state.messages,
                model=st.session_state.selected_model,
                temperature=st.session_state.temperature,
            )

            placeholder.markdown(response)
            full_response = response

        # Salvar no hist√≥rico
        st.session_state.messages.append(
            {"role": "assistant", "content": full_response}
        )

        # Recarregar para atualizar a interface
        st.rerun()

# ========== √ÅREA PRINCIPAL - DASHBOARD ==========
# √Årea principal para exibir conte√∫do/dashboards
main_area = st.container()

with main_area:
    if not st.session_state.messages:
        # Estado vazio - mostrar √≠cone e mensagem
        st.markdown(
            """
            <div class="empty-dashboard">
                <div class="dashboard-icon">
                    <svg viewBox="0 0 200 150" xmlns="http://www.w3.org/2000/svg">
                        <!-- Ret√¢ngulo principal com bordas arredondadas -->
                        <rect x="10" y="10" width="180" height="130" rx="8" ry="8" 
                              fill="none" stroke="#999" stroke-width="2"/>
                        <!-- Painel superior horizontal -->
                        <rect x="20" y="20" width="160" height="30" rx="4" ry="4" 
                              fill="#e0e0e0" stroke="#ccc" stroke-width="1"/>
                        <!-- Painel esquerdo vertical -->
                        <rect x="20" y="60" width="70" height="70" rx="4" ry="4" 
                              fill="#e0e0e0" stroke="#ccc" stroke-width="1"/>
                        <!-- Painel inferior direito (quadrado) -->
                        <rect x="100" y="100" width="80" height="30" rx="4" ry="4" 
                              fill="#e0e0e0" stroke="#ccc" stroke-width="1"/>
                        <!-- Painel superior direito -->
                        <rect x="100" y="60" width="80" height="30" rx="4" ry="4" 
                              fill="#e0e0e0" stroke="#ccc" stroke-width="1"/>
                    </svg>
                </div>
                <div class="empty-text">Nenhum dashboard gerado</div>
                <div class="empty-text-secondary">Envie uma mensagem no chat para come√ßar</div>
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        # Exibir conte√∫do das respostas
        # Se a √∫ltima mensagem for do assistente, mostrar em destaque
        if (
            st.session_state.messages
            and st.session_state.messages[-1]["role"] == "assistant"
        ):
            last_response = st.session_state.messages[-1]["content"]

            # Container para resposta
            st.markdown("### üìä Resposta do Assistente")
            st.markdown("---")

            # Exibir resposta formatada
            response_container = st.container()
            with response_container:
                st.markdown(last_response)

                # Bot√µes de a√ß√£o - apenas √≠cones
                col1, col2, col3 = st.columns(3)

                with col1:
                    if st.button("üîÑ", use_container_width=True, key="btn_regenerar"):
                        # Remove √∫ltima resposta e regenera
                        if len(st.session_state.messages) >= 2:
                            st.session_state.messages.pop()
                            st.session_state.messages.pop()
                            st.rerun()

                with col2:
                    if st.button("üìã", use_container_width=True, key="btn_copiar"):
                        st.success("Resposta copiada!")

                with col3:
                    if st.button("üóëÔ∏è", use_container_width=True, key="btn_limpar"):
                        st.session_state.messages = []
                        st.rerun()

        # Hist√≥rico completo (colaps√°vel)
        if len(st.session_state.messages) > 2:
            with st.expander("üìú Hist√≥rico Completo da Conversa"):
                for i, message in enumerate(st.session_state.messages):
                    role_icon = "üë§" if message["role"] == "user" else "ü§ñ"
                    st.markdown(f"**{role_icon} {message['role'].title()}:**")
                    st.markdown(message["content"])
                    if i < len(st.session_state.messages) - 1:
                        st.markdown("---")

    # Prompt no centro (se configurado)
    if st.session_state.prompt_in_center:
        st.markdown("<br><br>", unsafe_allow_html=True)  # Espa√ßo antes do prompt

        # Mostrar indicador de pensando acima do prompt se estiver pensando
        if st.session_state.is_thinking:
            st.markdown(
                '<div class="thinking-indicator">üí≠ <em>Pensando...</em></div>',
                unsafe_allow_html=True,
            )

        # Input de mensagem no centro
        center_user_input = st.chat_input(
            "Digite sua mensagem no centro...", key="center_chat_input"
        )

        # Microfone no centro
        center_audio_file = st.audio_input(
            "üéôÔ∏è", key="center_audio", help="Clique para gravar uma mensagem de voz"
        )

        # Processar √°udio se fornecido
        if center_audio_file:
            st.audio(center_audio_file, format="audio/wav")
            with st.spinner("Transcrevendo √°udio..."):
                try:
                    if AUDIO_AVAILABLE:
                        transcribed_text = transcribe_audio(
                            center_audio_file,
                            method=st.session_state.transcription_method,
                        )
                        if transcribed_text:
                            st.session_state.audio_transcribed = transcribed_text
                        else:
                            st.error(
                                "‚ùå Erro ao transcrever √°udio. Verifique se o servi√ßo est√° configurado."
                            )
                    else:
                        st.warning(
                            "‚ö†Ô∏è Transcri√ß√£o de √°udio n√£o dispon√≠vel. Instale as depend√™ncias necess√°rias."
                        )
                except Exception as e:
                    st.error(f"‚ùå Erro na transcri√ß√£o: {str(e)}")

            if st.session_state.audio_transcribed:
                st.info(
                    f"üìù Transcri√ß√£o do √°udio: **{st.session_state.audio_transcribed}**"
                )
                # Se houver transcri√ß√£o, usar como input
                if not center_user_input:
                    center_user_input = st.session_state.audio_transcribed
                    st.session_state.audio_transcribed = None  # Limpar ap√≥s usar

        # Processar mensagem quando enviada do centro
        if center_user_input:
            if (
                st.session_state.llm_handler is None
                or not st.session_state.llm_handler.is_configured()
            ):
                st.error(
                    "‚ö†Ô∏è Ollama n√£o est√° dispon√≠vel. Verifique se o servidor est√° rodando."
                )
            else:
                # Adicionar mensagem do usu√°rio no hist√≥rico
                st.session_state.messages.append(
                    {"role": "user", "content": center_user_input}
                )

                # Exibir imediatamente a mensagem do usu√°rio
                with st.chat_message("user"):
                    st.markdown(center_user_input)

                # Gerar resposta em streaming
                with st.chat_message("assistant"):
                    placeholder = st.empty()
                    full_response = ""

                    # Gerar resposta
                    response = st.session_state.llm_handler.generate_response(
                        messages=st.session_state.messages,
                        model=st.session_state.selected_model,
                        temperature=st.session_state.temperature,
                    )

                    placeholder.markdown(response)
                    full_response = response

                # Salvar no hist√≥rico
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )

                # Recarregar para atualizar a interface
                st.rerun()
