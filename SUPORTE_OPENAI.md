# üöÄ Suporte a Modelos OpenAI - Documenta√ß√£o

## üìã Resumo

Foi adicionado suporte completo para modelos LLM da OpenAI no projeto, permitindo escolher entre modelos locais (Ollama) e modelos da OpenAI.

## ‚ú® Funcionalidades Adicionadas

### 1. Sele√ß√£o de Provedor
- **Ollama**: Modelos locais (padr√£o)
- **OpenAI**: Modelos da OpenAI (gpt-4o, gpt-3.5-turbo, etc.)

### 2. Modelos OpenAI Dispon√≠veis
- `gpt-4o` - Modelo mais avan√ßado
- `gpt-4o-mini` - Vers√£o mais r√°pida e econ√¥mica
- `gpt-4-turbo` - Vers√£o turbo do GPT-4
- `gpt-4` - GPT-4 padr√£o
- `gpt-3.5-turbo` - Modelo r√°pido e econ√¥mico
- `gpt-3.5-turbo-16k` - Vers√£o com contexto maior

## üìÅ Arquivos Criados

1. **`src/core/openai_service.py`**
   - Servi√ßo para comunica√ß√£o com a API da OpenAI
   - Similar ao `ollama_service.py`
   - Suporta chat com hist√≥rico e streaming

2. **`src/core/openai_handler.py`**
   - Handler que adapta OpenAIService para a interface do app.py
   - Similar ao `llm_handler.py`
   - Implementa a mesma interface para compatibilidade

## üîß Como Usar

### 1. Configurar API Key da OpenAI

**Op√ß√£o A: Arquivo .env (Recomendado)**
```env
OPENAI_API_KEY=sk-sua-chave-api-aqui
```

**Op√ß√£o B: Interface do Streamlit**
- V√° em "‚öôÔ∏è Configura√ß√µes"
- Selecione "openai" como provedor
- Digite sua API key no campo "OpenAI API Key"

### 2. Selecionar Provedor

1. Abra a aplica√ß√£o Streamlit
2. Na sidebar, expanda "‚öôÔ∏è Configura√ß√µes"
3. Em "ü§ñ Provedor de IA", escolha:
   - **Ollama**: Para modelos locais
   - **OpenAI**: Para modelos da OpenAI

### 3. Conectar √† OpenAI

1. Selecione "OpenAI" como provedor
2. Configure sua API key (se ainda n√£o estiver no .env)
3. Clique em "üîÑ Conectar √† OpenAI"
4. Aguarde a confirma√ß√£o de conex√£o

### 4. Selecionar Modelo

Ap√≥s conectar, voc√™ ver√° a lista de modelos dispon√≠veis:
- **Ollama**: Modelos instalados localmente
- **OpenAI**: Modelos dispon√≠veis da OpenAI

## üéØ Diferen√ßas entre Ollama e OpenAI

| Caracter√≠stica | Ollama | OpenAI |
|----------------|--------|--------|
| **Localiza√ß√£o** | Local | Nuvem |
| **Custo** | Gratuito | Pago por uso |
| **Velocidade** | Depende do hardware | R√°pido |
| **Privacidade** | Totalmente local | Dados enviados √† OpenAI |
| **Modelos** | Modelos open-source | Modelos propriet√°rios |
| **Internet** | N√£o requer | Requer conex√£o |

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

```env
# Ollama (opcional, padr√£o: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120

# OpenAI (obrigat√≥rio para usar OpenAI)
OPENAI_API_KEY=sk-sua-chave-api-aqui
```

### Timeout

O timeout √© compartilhado entre Ollama e OpenAI e pode ser configurado via:
- Vari√°vel de ambiente `OLLAMA_TIMEOUT`
- Arquivo `model_config.py`

## üîç Status da Conex√£o

O status mostra:
- ‚úÖ **Conectado**: Provedor funcionando corretamente
- ‚ùå **Erro**: Problema de conex√£o ou configura√ß√£o
- üì¶ **Modelos**: Quantidade de modelos dispon√≠veis
- üí° **Sugest√µes**: Dicas para resolver problemas

## üêõ Solu√ß√£o de Problemas

### "OPENAI_API_KEY n√£o configurada"
**Solu√ß√£o**: Configure a API key no arquivo `.env` ou na interface

### "Erro ao conectar √† OpenAI"
**Solu√ß√µes**:
1. Verifique se a API key est√° correta
2. Verifique sua conex√£o com a internet
3. Verifique se sua conta OpenAI tem cr√©ditos dispon√≠veis

### "Nenhum modelo dispon√≠vel"
**Solu√ß√£o**: 
- Para Ollama: Baixe modelos com `ollama pull <modelo>`
- Para OpenAI: Verifique sua API key e conex√£o

## üìù Notas Importantes

1. **Custos**: O uso da OpenAI API √© pago. Verifique os pre√ßos em https://openai.com/pricing
2. **Privacidade**: Dados enviados √† OpenAI s√£o processados em seus servidores
3. **Rate Limits**: A OpenAI tem limites de requisi√ß√µes por minuto/hora
4. **Modelos**: Alguns modelos podem n√£o estar dispon√≠veis dependendo da sua conta

## üîÑ Alternando entre Provedores

Voc√™ pode alternar entre Ollama e OpenAI a qualquer momento:
1. V√° em "‚öôÔ∏è Configura√ß√µes"
2. Selecione o provedor desejado
3. Configure e conecte
4. Selecione o modelo

O hist√≥rico de conversas √© mantido ao alternar entre provedores.

## üöÄ Pr√≥ximos Passos

- [ ] Adicionar mais modelos OpenAI (quando dispon√≠veis)
- [ ] Suporte a streaming na UI
- [ ] Cache de respostas
- [ ] M√©tricas de uso e custos

---

**Desenvolvido para o Projeto IAG - Chat Assistente com IA**

